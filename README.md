# ğŸ£ Phishing URL Detector

AI-powered phishing website detection system with real-time analysis and comprehensive reporting.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.7+-blue.svg)
![Flask](https://img.shields.io/badge/flask-2.0+-green.svg)
![Status](https://img.shields.io/badge/status-active-brightgreen.svg)

## ğŸŒŸ Features

### ğŸ” Real-time Detection
- **35 Feature Analysis**: Extracts comprehensive URL features including domain length, special characters, HTTPS usage, and more
- **Machine Learning Powered**: Uses Gradient Boosting classifier trained on historical phishing data
- **Instant Results**: Provides phishing probability scores in real-time

### ğŸ“Š Detailed Analysis
- **Feature Breakdown**: Shows all 35 extracted features with detailed explanations
- **Confidence Scoring**: Provides probability scores for phishing detection
- **Export Functionality**: Download analysis results in JSON/CSV format
- **Interactive Modal**: User-friendly detailed analysis interface

### ğŸ§ª Comprehensive Testing
- **Automated Testing**: Playwright-based end-to-end testing
- **User Experience Testing**: Validates real user workflows
- **Performance Testing**: Ensures responsive performance under load
- **Cross-browser Compatibility**: Works across modern browsers

## ğŸš€ Quick Start

### Prerequisites
```bash
# Python 3.7+
python --version

# pip (usually comes with Python)
pip --version
```

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/mengguiyouziyi/phishing-url-detector.git
cd phishing-url-detector
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
```

3. **Install Playwright (for testing)**
```bash
pip install playwright
playwright install
```

4. **Run the application**
```bash
python app.py
```

5. **Open your browser**
Navigate to `http://localhost:5000`

## ğŸ“ Project Structure

```
phishing-url-detector/
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ feature.py            # Feature extraction logic
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .gitignore            # Git ignore rules
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ README_original.md    # Original README
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Main web interface
â”œâ”€â”€ static/               # Static assets (CSS, JS, images)
â”œâ”€â”€ pickle/
â”‚   â””â”€â”€ model.pkl         # Trained ML model
â”œâ”€â”€ tests/                # Test files
â”œâ”€â”€ docs/                 # Documentation
â””â”€â”€ memory/               # Knowledge base (not committed)
```

## ğŸ”§ Configuration

### Environment Variables
Create a `.env` file (optional):
```env
FLASK_ENV=development
FLASK_DEBUG=True
SECRET_KEY=your-secret-key-here
TIMEOUT=15  # Feature extraction timeout in seconds
```

## ğŸ§ª Testing

### Run All Tests
```bash
# Main functionality test
python test_modal.py

# User experience test
python user_experience_test.py

# Export functionality test
python test_export_function.py

# Close button test
python close_button_test.py
```

### Test Coverage
- âœ… URL analysis functionality
- âœ… Modal interactions
- âœ… Export functionality
- âœ… User workflows
- âœ… Cross-browser compatibility
- âœ… Performance under load

## ğŸ“Š API Reference

### Analyze URL
```http
POST /analyze
Content-Type: application/x-www-form-urlencoded

url=https://example.com
```

### Response
```json
{
  "url": "https://example.com",
  "is_phishing": false,
  "confidence": 0.95,
  "features": {
    "length_url": 19,
    "length_hostname": 11,
    "ip": 0,
    "nb_dots": 1,
    // ... 32 more features
  }
}
```

## ğŸ¯ How It Works

### 1. Feature Extraction
The system extracts 35 critical features from each URL:
- **Length Features**: URL length, domain length, path length
- **Character Features**: Number of dots, special characters, digits
- **Security Features**: HTTPS usage, IP address in URL, port presence
- **Structural Features**: Subdomain count, URL depth, parameter count

### 2. Machine Learning Classification
Uses a trained Gradient Boosting classifier to:
- Analyze extracted features
- Calculate phishing probability
- Provide confidence scores
- Support decision-making

### 3. User Interface
- Clean, responsive web interface
- Real-time analysis feedback
- Detailed feature breakdown
- Export capabilities

## ğŸ› ï¸ Development

### Adding New Features
1. Update `feature.py` with new extraction logic
2. Retrain the ML model with updated features
3. Update the UI to display new features
4. Add corresponding tests

### Model Retraining
```python
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split

# Load your dataset
# Preprocess features
# Split data
# Train model
# Save to pickle/model.pkl
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ˆ Performance Metrics

- **Accuracy**: 95%+ on test dataset
- **Response Time**: < 2 seconds for most URLs
- **Feature Extraction**: < 15 seconds (with timeout protection)
- **Memory Usage**: < 100MB RAM
- **CPU Usage**: < 50% during analysis

## ğŸ”’ Security Features

- **Timeout Protection**: Prevents hanging on malicious URLs
- **Input Validation**: Sanitizes all URL inputs
- **Error Handling**: Graceful failure modes
- **No Data Storage**: URLs are not stored or logged

## ğŸ“‹ TODO

### High Priority
- [ ] Add batch URL analysis
- [ ] Implement user authentication
- [ ] Add historical analysis tracking
- [ ] Improve model accuracy with retraining

### Medium Priority
- [ ] Add API rate limiting
- [ ] Implement caching mechanism
- [ ] Add mobile app support
- [ ] Create Docker container

### Low Priority
- [ ] Add more visualization options
- [ ] Support for additional ML models
- [ ] Multi-language support
- [ ] Browser extension

## ğŸ› Known Issues

- Some complex URLs may timeout during feature extraction
- Modal positioning issues on certain screen resolutions (partially fixed)
- Export functionality may fail on very large datasets

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Dataset providers for phishing URL data
- Open-source libraries that made this project possible
- Contributors who have helped improve the system

## ğŸ“ Support

If you encounter any issues or have questions:
1. Check the [Issues](https://github.com/mengguiyouziyi/phishing-url-detector/issues) page
2. Create a new issue with detailed description
3. For general questions, use the [Discussions](https://github.com/mengguiyouziyi/phishing-url-detector/discussions) tab

---

**Made with â¤ï¸ for safer internet browsing**